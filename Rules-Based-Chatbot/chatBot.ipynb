{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55781c6e-4242-424b-8346-f611890327fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harshil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/harshil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8426d488-7763-48e6-960a-16548c320f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Knowledge Base from pickle files\n",
    "with open('knowledgeBase.pickle', 'rb') as handle:\n",
    "    KB = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ddbc2a-bf22-4c23-af4b-d88d3c657b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user model if exists\n",
    "file_path = 'userModel.pickle'\n",
    "if os.path.exists(file_path):\n",
    "    # File exists, open it\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        userModel = pickle.load(handle)\n",
    "else:\n",
    "    # File does not exist, create it\n",
    "    f = open(file_path, \"x\")\n",
    "    f.close()\n",
    "    userModel = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0102796d-3a8e-4ba4-a8e5-090aa4d638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Greeting function\n",
    "greet_inputs = ('hello', 'hi', 'how are you?')\n",
    "greet_responses = ('hi', 'Hey', 'Hey There!')\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in greet_inputs:\n",
    "            return random.choice(greet_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86014b82-457b-4416-94d3-989c18168a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text PreProcessing\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punc_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa57a41d-fee2-46e3-a4de-6e928f022afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining response\n",
    "def response(user_response):\n",
    "    filmy_response = ''\n",
    "    user_response_tokens = LemNormalize(user_response)\n",
    "    response_sentences = []\n",
    "    for token in user_response_tokens:\n",
    "        if token in KB:\n",
    "            response_sentences.extend(KB[token])\n",
    "    response_sentences.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "    tfidf = TfidfVec.fit_transform(response_sentences)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    if len(vals[0]) < 2:\n",
    "        filmy_response += \"I am sorry, unable to understand you.\"\n",
    "        return filmy_response \n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if req_tfidf == 0:\n",
    "        filmy_response += \"I am sorry, unable to understand you.\"\n",
    "        return filmy_response\n",
    "    else:\n",
    "        filmy_response += response_sentences[idx]\n",
    "        return filmy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dbb9968-9f14-4bea-b52f-0e9f1a84a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract name\n",
    "def extractName(user_response):\n",
    "    # Extract names using named entity recognition\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(user_response)\n",
    "    \n",
    "    # Perform part-of-speech tagging\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    # Use NLTK's named entity recognition (NER) to extract named entities\n",
    "    named_entities = nltk.ne_chunk(pos_tags)\n",
    "    \n",
    "    # Initialize a list to store extracted names\n",
    "    name = ''\n",
    "    \n",
    "    # Traverse the named entities tree and extract Named entities\n",
    "    for entity in named_entities:\n",
    "        if entity[0] == 'i' or entity[0] == 'my':\n",
    "            continue\n",
    "        if len(entity) > 1:\n",
    "            if entity[1] == 'NN' or entity[1] == 'JJ':\n",
    "                name += entity[0]\n",
    "        else:\n",
    "            if isinstance(entity, nltk.tree.Tree) and (entity.label() == 'PERSON' or entity.label() == 'ORGANIZATION'):\n",
    "                name += ' '.join([token[0] for token in entity.leaves()])\n",
    "            \n",
    "    if not name:\n",
    "        name += words[-1]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110e1b6b-912f-4454-ad78-787546a4f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Chat Flow\n",
    "def FilmyBot():\n",
    "    flag = True\n",
    "    print('Bot: Hello! I am FilmyBot, your guide on Bollywood. For ending the convo type bye!')\n",
    "    print('Bot: For starters, what is your name?')\n",
    "    \n",
    "    user_response = input()\n",
    "    name = extractName(user_response.lower())\n",
    "    if name in userModel:\n",
    "        print(f'Bot: Hi {name}. Welcome back! Happy to chat more about bollywood with you today!')\n",
    "    else:\n",
    "        print(f'Bot: Hi {name}. Happy to have you onboard this very Dhamakedar experience!')\n",
    "        userModel[name] = {\"likes\": \"\", \"dislikes\": \"\"}\n",
    "        print('Bot: What do you like about Bollywood?')\n",
    "        user_response = input().lower()\n",
    "        userModel[name][\"likes\"] = user_response\n",
    "        print('Bot: Ok nice! Now what do you disike about Bollywood?')\n",
    "        user_response = input().lower()\n",
    "        userModel[name][\"dislikes\"] = user_response   \n",
    "        print('Bot: Fantastic! I am happy to learn more about you. Blast off any questions who have')\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(userModel, handle)\n",
    "    \n",
    "    while(flag == True):\n",
    "        user_response = input()\n",
    "        user_response = user_response.lower()\n",
    "        if(user_response != 'bye'):\n",
    "            if(user_response == 'thank you' or user_response == 'thanks'):\n",
    "                flag = False\n",
    "                print('Bot: You are Welcome..')\n",
    "            else:\n",
    "                if(greet(user_response) != None):\n",
    "                    print('Bot '+ greet(user_response))\n",
    "                else:\n",
    "                    print('Bot: ', end = '')\n",
    "                    print(response(user_response))\n",
    "        else:\n",
    "            flag = False\n",
    "            print ('Bot: Goodbye!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fb1ab2-8782-45b0-a6ef-f050ae612990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! I am FilmyBot, your guide on Bollywood. For ending the convo type bye!\n",
      "Bot: For starters, what is your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Raaed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi raaed. Happy to have you onboard this very Dhamakedar experience!\n",
      "Bot: What do you like about Bollywood?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I like 2000s coming of age movies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Ok nice! Now what do you disike about Bollywood?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Salman Khan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Fantastic! I am happy to learn more about you. Blast off any questions who have\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Amitabh Bachchan's famous movies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshil/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/harshil/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, unable to understand you.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What are Salman Khan best movies? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  the most popular actors in pakistan are the three khans of bollywood: salman, shah rukh, and aamir.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " aamir best movies recently\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I am sorry, unable to understand you.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " aamir khan movies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  the most popular actors in pakistan are the three khans of bollywood: salman, shah rukh, and aamir.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Call Filmy bot using the following command\n",
    "FilmyBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6f1d46e-9c53-4996-892f-cfa6ef8f0433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! I am FilmyBot, your guide on Bollywood. For ending the convo type bye!\n",
      "Bot: For starters, what is your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " raaed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi raaed. Welcome back! Happy to chat more about bollywood with you today!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: You are Welcome..\n"
     ]
    }
   ],
   "source": [
    "# Call Filmy bot using the following command\n",
    "FilmyBot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
